// SPDX-FileCopyrightText: 2024 The Crossplane Authors <https://crossplane.io>
//
// SPDX-License-Identifier: Apache-2.0

// Code generated by upjet. DO NOT EDIT.

package v1alpha1

import (
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/runtime/schema"

	v1 "github.com/crossplane/crossplane-runtime/apis/common/v1"
)

type NotificationsOnNewClassificationTagDetectedInitParameters struct {
	EmailAddresses []*string `json:"emailAddresses,omitempty" tf:"email_addresses,omitempty"`
}

type NotificationsOnNewClassificationTagDetectedObservation struct {
	EmailAddresses []*string `json:"emailAddresses,omitempty" tf:"email_addresses,omitempty"`
}

type NotificationsOnNewClassificationTagDetectedParameters struct {

	// +kubebuilder:validation:Optional
	EmailAddresses []*string `json:"emailAddresses,omitempty" tf:"email_addresses,omitempty"`
}

type QualityMonitorCustomMetricsInitParameters struct {

	// create metric definition
	Definition *string `json:"definition,omitempty" tf:"definition,omitempty"`

	// Columns on the monitored table to apply the custom metrics to.
	InputColumns []*string `json:"inputColumns,omitempty" tf:"input_columns,omitempty"`

	// Name of the custom metric.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// The output type of the custom metric.
	OutputDataType *string `json:"outputDataType,omitempty" tf:"output_data_type,omitempty"`

	// The type of the custom metric.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type QualityMonitorCustomMetricsObservation struct {

	// create metric definition
	Definition *string `json:"definition,omitempty" tf:"definition,omitempty"`

	// Columns on the monitored table to apply the custom metrics to.
	InputColumns []*string `json:"inputColumns,omitempty" tf:"input_columns,omitempty"`

	// Name of the custom metric.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// The output type of the custom metric.
	OutputDataType *string `json:"outputDataType,omitempty" tf:"output_data_type,omitempty"`

	// The type of the custom metric.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type QualityMonitorCustomMetricsParameters struct {

	// create metric definition
	// +kubebuilder:validation:Optional
	Definition *string `json:"definition" tf:"definition,omitempty"`

	// Columns on the monitored table to apply the custom metrics to.
	// +kubebuilder:validation:Optional
	InputColumns []*string `json:"inputColumns" tf:"input_columns,omitempty"`

	// Name of the custom metric.
	// +kubebuilder:validation:Optional
	Name *string `json:"name" tf:"name,omitempty"`

	// The output type of the custom metric.
	// +kubebuilder:validation:Optional
	OutputDataType *string `json:"outputDataType" tf:"output_data_type,omitempty"`

	// The type of the custom metric.
	// +kubebuilder:validation:Optional
	Type *string `json:"type" tf:"type,omitempty"`
}

type QualityMonitorDataClassificationConfigInitParameters struct {
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`
}

type QualityMonitorDataClassificationConfigObservation struct {
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`
}

type QualityMonitorDataClassificationConfigParameters struct {

	// +kubebuilder:validation:Optional
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`
}

type QualityMonitorInferenceLogInitParameters struct {

	// List of granularities to use when aggregating data into time windows based on their timestamp.
	Granularities []*string `json:"granularities,omitempty" tf:"granularities,omitempty"`

	// Column of the model label
	LabelCol *string `json:"labelCol,omitempty" tf:"label_col,omitempty"`

	// Column of the model id or version
	ModelIDCol *string `json:"modelIdCol,omitempty" tf:"model_id_col,omitempty"`

	// Column of the model prediction
	PredictionCol *string `json:"predictionCol,omitempty" tf:"prediction_col,omitempty"`

	// Column of the model prediction probabilities
	PredictionProbaCol *string `json:"predictionProbaCol,omitempty" tf:"prediction_proba_col,omitempty"`

	// Problem type the model aims to solve. Either PROBLEM_TYPE_CLASSIFICATION or PROBLEM_TYPE_REGRESSION
	ProblemType *string `json:"problemType,omitempty" tf:"problem_type,omitempty"`

	// Column of the timestamp of predictions
	TimestampCol *string `json:"timestampCol,omitempty" tf:"timestamp_col,omitempty"`
}

type QualityMonitorInferenceLogObservation struct {

	// List of granularities to use when aggregating data into time windows based on their timestamp.
	Granularities []*string `json:"granularities,omitempty" tf:"granularities,omitempty"`

	// Column of the model label
	LabelCol *string `json:"labelCol,omitempty" tf:"label_col,omitempty"`

	// Column of the model id or version
	ModelIDCol *string `json:"modelIdCol,omitempty" tf:"model_id_col,omitempty"`

	// Column of the model prediction
	PredictionCol *string `json:"predictionCol,omitempty" tf:"prediction_col,omitempty"`

	// Column of the model prediction probabilities
	PredictionProbaCol *string `json:"predictionProbaCol,omitempty" tf:"prediction_proba_col,omitempty"`

	// Problem type the model aims to solve. Either PROBLEM_TYPE_CLASSIFICATION or PROBLEM_TYPE_REGRESSION
	ProblemType *string `json:"problemType,omitempty" tf:"problem_type,omitempty"`

	// Column of the timestamp of predictions
	TimestampCol *string `json:"timestampCol,omitempty" tf:"timestamp_col,omitempty"`
}

type QualityMonitorInferenceLogParameters struct {

	// List of granularities to use when aggregating data into time windows based on their timestamp.
	// +kubebuilder:validation:Optional
	Granularities []*string `json:"granularities" tf:"granularities,omitempty"`

	// Column of the model label
	// +kubebuilder:validation:Optional
	LabelCol *string `json:"labelCol,omitempty" tf:"label_col,omitempty"`

	// Column of the model id or version
	// +kubebuilder:validation:Optional
	ModelIDCol *string `json:"modelIdCol" tf:"model_id_col,omitempty"`

	// Column of the model prediction
	// +kubebuilder:validation:Optional
	PredictionCol *string `json:"predictionCol" tf:"prediction_col,omitempty"`

	// Column of the model prediction probabilities
	// +kubebuilder:validation:Optional
	PredictionProbaCol *string `json:"predictionProbaCol,omitempty" tf:"prediction_proba_col,omitempty"`

	// Problem type the model aims to solve. Either PROBLEM_TYPE_CLASSIFICATION or PROBLEM_TYPE_REGRESSION
	// +kubebuilder:validation:Optional
	ProblemType *string `json:"problemType" tf:"problem_type,omitempty"`

	// Column of the timestamp of predictions
	// +kubebuilder:validation:Optional
	TimestampCol *string `json:"timestampCol" tf:"timestamp_col,omitempty"`
}

type QualityMonitorInitParameters struct {

	// - The directory to store the monitoring assets (Eg. Dashboard and Metric Tables)
	AssetsDir *string `json:"assetsDir,omitempty" tf:"assets_dir,omitempty"`

	// Name of the baseline table from which drift metrics are computed from.Columns in the monitored table should also be present in the baseline
	// table.
	BaselineTableName *string `json:"baselineTableName,omitempty" tf:"baseline_table_name,omitempty"`

	// Custom metrics to compute on the monitored table. These can be aggregate metrics, derived metrics (from already computed aggregate metrics), or drift metrics (comparing metrics across time windows).
	CustomMetrics []QualityMonitorCustomMetricsInitParameters `json:"customMetrics,omitempty" tf:"custom_metrics,omitempty"`

	// The data classification config for the monitor
	DataClassificationConfig []QualityMonitorDataClassificationConfigInitParameters `json:"dataClassificationConfig,omitempty" tf:"data_classification_config,omitempty"`

	// Configuration for the inference log monitor
	InferenceLog []QualityMonitorInferenceLogInitParameters `json:"inferenceLog,omitempty" tf:"inference_log,omitempty"`

	LatestMonitorFailureMsg *string `json:"latestMonitorFailureMsg,omitempty" tf:"latest_monitor_failure_msg,omitempty"`

	// The notification settings for the monitor.  The following optional blocks are supported, each consisting of the single string array field with name email_addresses containing a list of emails to notify:
	Notifications []QualityMonitorNotificationsInitParameters `json:"notifications,omitempty" tf:"notifications,omitempty"`

	// - Schema where output metric tables are created
	OutputSchemaName *string `json:"outputSchemaName,omitempty" tf:"output_schema_name,omitempty"`

	// The schedule for automatically updating and refreshing metric tables.  This block consists of following fields:
	Schedule []QualityMonitorScheduleInitParameters `json:"schedule,omitempty" tf:"schedule,omitempty"`

	// Whether to skip creating a default dashboard summarizing data quality metrics.
	SkipBuiltinDashboard *bool `json:"skipBuiltinDashboard,omitempty" tf:"skip_builtin_dashboard,omitempty"`

	// List of column expressions to slice data with for targeted analysis. The data is grouped by each expression independently, resulting in a separate slice for each predicate and its complements. For high-cardinality columns, only the top 100 unique values by frequency will generate slices.
	SlicingExprs []*string `json:"slicingExprs,omitempty" tf:"slicing_exprs,omitempty"`

	// Configuration for monitoring snapshot tables.
	Snapshot []QualityMonitorSnapshotInitParameters `json:"snapshot,omitempty" tf:"snapshot,omitempty"`

	// - The full name of the table to attach the monitor too. Its of the format {catalog}.{schema}.{tableName}
	TableName *string `json:"tableName,omitempty" tf:"table_name,omitempty"`

	// Configuration for monitoring timeseries tables.
	TimeSeries []QualityMonitorTimeSeriesInitParameters `json:"timeSeries,omitempty" tf:"time_series,omitempty"`

	// Optional argument to specify the warehouse for dashboard creation. If not specified, the first running warehouse will be used.
	WarehouseID *string `json:"warehouseId,omitempty" tf:"warehouse_id,omitempty"`
}

type QualityMonitorNotificationsInitParameters struct {

	// who to send notifications to on monitor failure.
	OnFailure []QualityMonitorNotificationsOnFailureInitParameters `json:"onFailure,omitempty" tf:"on_failure,omitempty"`

	// Who to send notifications to when new data classification tags are detected.
	OnNewClassificationTagDetected []NotificationsOnNewClassificationTagDetectedInitParameters `json:"onNewClassificationTagDetected,omitempty" tf:"on_new_classification_tag_detected,omitempty"`
}

type QualityMonitorNotificationsObservation struct {

	// who to send notifications to on monitor failure.
	OnFailure []QualityMonitorNotificationsOnFailureObservation `json:"onFailure,omitempty" tf:"on_failure,omitempty"`

	// Who to send notifications to when new data classification tags are detected.
	OnNewClassificationTagDetected []NotificationsOnNewClassificationTagDetectedObservation `json:"onNewClassificationTagDetected,omitempty" tf:"on_new_classification_tag_detected,omitempty"`
}

type QualityMonitorNotificationsOnFailureInitParameters struct {
	EmailAddresses []*string `json:"emailAddresses,omitempty" tf:"email_addresses,omitempty"`
}

type QualityMonitorNotificationsOnFailureObservation struct {
	EmailAddresses []*string `json:"emailAddresses,omitempty" tf:"email_addresses,omitempty"`
}

type QualityMonitorNotificationsOnFailureParameters struct {

	// +kubebuilder:validation:Optional
	EmailAddresses []*string `json:"emailAddresses,omitempty" tf:"email_addresses,omitempty"`
}

type QualityMonitorNotificationsParameters struct {

	// who to send notifications to on monitor failure.
	// +kubebuilder:validation:Optional
	OnFailure []QualityMonitorNotificationsOnFailureParameters `json:"onFailure,omitempty" tf:"on_failure,omitempty"`

	// Who to send notifications to when new data classification tags are detected.
	// +kubebuilder:validation:Optional
	OnNewClassificationTagDetected []NotificationsOnNewClassificationTagDetectedParameters `json:"onNewClassificationTagDetected,omitempty" tf:"on_new_classification_tag_detected,omitempty"`
}

type QualityMonitorObservation struct {

	// - The directory to store the monitoring assets (Eg. Dashboard and Metric Tables)
	AssetsDir *string `json:"assetsDir,omitempty" tf:"assets_dir,omitempty"`

	// Name of the baseline table from which drift metrics are computed from.Columns in the monitored table should also be present in the baseline
	// table.
	BaselineTableName *string `json:"baselineTableName,omitempty" tf:"baseline_table_name,omitempty"`

	// Custom metrics to compute on the monitored table. These can be aggregate metrics, derived metrics (from already computed aggregate metrics), or drift metrics (comparing metrics across time windows).
	CustomMetrics []QualityMonitorCustomMetricsObservation `json:"customMetrics,omitempty" tf:"custom_metrics,omitempty"`

	// The ID of the generated dashboard.
	DashboardID *string `json:"dashboardId,omitempty" tf:"dashboard_id,omitempty"`

	// The data classification config for the monitor
	DataClassificationConfig []QualityMonitorDataClassificationConfigObservation `json:"dataClassificationConfig,omitempty" tf:"data_classification_config,omitempty"`

	// The full name of the drift metrics table. Format: catalog_name.schema_name.table_name.
	DriftMetricsTableName *string `json:"driftMetricsTableName,omitempty" tf:"drift_metrics_table_name,omitempty"`

	// ID of this monitor is the same as the full table name of the format {catalog}.{schema_name}.{table_name}
	ID *string `json:"id,omitempty" tf:"id,omitempty"`

	// Configuration for the inference log monitor
	InferenceLog []QualityMonitorInferenceLogObservation `json:"inferenceLog,omitempty" tf:"inference_log,omitempty"`

	LatestMonitorFailureMsg *string `json:"latestMonitorFailureMsg,omitempty" tf:"latest_monitor_failure_msg,omitempty"`

	// The version of the monitor config (e.g. 1,2,3). If negative, the monitor may be corrupted
	MonitorVersion *string `json:"monitorVersion,omitempty" tf:"monitor_version,omitempty"`

	// The notification settings for the monitor.  The following optional blocks are supported, each consisting of the single string array field with name email_addresses containing a list of emails to notify:
	Notifications []QualityMonitorNotificationsObservation `json:"notifications,omitempty" tf:"notifications,omitempty"`

	// - Schema where output metric tables are created
	OutputSchemaName *string `json:"outputSchemaName,omitempty" tf:"output_schema_name,omitempty"`

	// The full name of the profile metrics table. Format: catalog_name.schema_name.table_name.
	ProfileMetricsTableName *string `json:"profileMetricsTableName,omitempty" tf:"profile_metrics_table_name,omitempty"`

	// The schedule for automatically updating and refreshing metric tables.  This block consists of following fields:
	Schedule []QualityMonitorScheduleObservation `json:"schedule,omitempty" tf:"schedule,omitempty"`

	// Whether to skip creating a default dashboard summarizing data quality metrics.
	SkipBuiltinDashboard *bool `json:"skipBuiltinDashboard,omitempty" tf:"skip_builtin_dashboard,omitempty"`

	// List of column expressions to slice data with for targeted analysis. The data is grouped by each expression independently, resulting in a separate slice for each predicate and its complements. For high-cardinality columns, only the top 100 unique values by frequency will generate slices.
	SlicingExprs []*string `json:"slicingExprs,omitempty" tf:"slicing_exprs,omitempty"`

	// Configuration for monitoring snapshot tables.
	Snapshot []QualityMonitorSnapshotParameters `json:"snapshot,omitempty" tf:"snapshot,omitempty"`

	// Status of the Monitor
	Status *string `json:"status,omitempty" tf:"status,omitempty"`

	// - The full name of the table to attach the monitor too. Its of the format {catalog}.{schema}.{tableName}
	TableName *string `json:"tableName,omitempty" tf:"table_name,omitempty"`

	// Configuration for monitoring timeseries tables.
	TimeSeries []QualityMonitorTimeSeriesObservation `json:"timeSeries,omitempty" tf:"time_series,omitempty"`

	// Optional argument to specify the warehouse for dashboard creation. If not specified, the first running warehouse will be used.
	WarehouseID *string `json:"warehouseId,omitempty" tf:"warehouse_id,omitempty"`
}

type QualityMonitorParameters struct {

	// - The directory to store the monitoring assets (Eg. Dashboard and Metric Tables)
	// +kubebuilder:validation:Optional
	AssetsDir *string `json:"assetsDir,omitempty" tf:"assets_dir,omitempty"`

	// Name of the baseline table from which drift metrics are computed from.Columns in the monitored table should also be present in the baseline
	// table.
	// +kubebuilder:validation:Optional
	BaselineTableName *string `json:"baselineTableName,omitempty" tf:"baseline_table_name,omitempty"`

	// Custom metrics to compute on the monitored table. These can be aggregate metrics, derived metrics (from already computed aggregate metrics), or drift metrics (comparing metrics across time windows).
	// +kubebuilder:validation:Optional
	CustomMetrics []QualityMonitorCustomMetricsParameters `json:"customMetrics,omitempty" tf:"custom_metrics,omitempty"`

	// The data classification config for the monitor
	// +kubebuilder:validation:Optional
	DataClassificationConfig []QualityMonitorDataClassificationConfigParameters `json:"dataClassificationConfig,omitempty" tf:"data_classification_config,omitempty"`

	// Configuration for the inference log monitor
	// +kubebuilder:validation:Optional
	InferenceLog []QualityMonitorInferenceLogParameters `json:"inferenceLog,omitempty" tf:"inference_log,omitempty"`

	// +kubebuilder:validation:Optional
	LatestMonitorFailureMsg *string `json:"latestMonitorFailureMsg,omitempty" tf:"latest_monitor_failure_msg,omitempty"`

	// The notification settings for the monitor.  The following optional blocks are supported, each consisting of the single string array field with name email_addresses containing a list of emails to notify:
	// +kubebuilder:validation:Optional
	Notifications []QualityMonitorNotificationsParameters `json:"notifications,omitempty" tf:"notifications,omitempty"`

	// - Schema where output metric tables are created
	// +kubebuilder:validation:Optional
	OutputSchemaName *string `json:"outputSchemaName,omitempty" tf:"output_schema_name,omitempty"`

	// The schedule for automatically updating and refreshing metric tables.  This block consists of following fields:
	// +kubebuilder:validation:Optional
	Schedule []QualityMonitorScheduleParameters `json:"schedule,omitempty" tf:"schedule,omitempty"`

	// Whether to skip creating a default dashboard summarizing data quality metrics.
	// +kubebuilder:validation:Optional
	SkipBuiltinDashboard *bool `json:"skipBuiltinDashboard,omitempty" tf:"skip_builtin_dashboard,omitempty"`

	// List of column expressions to slice data with for targeted analysis. The data is grouped by each expression independently, resulting in a separate slice for each predicate and its complements. For high-cardinality columns, only the top 100 unique values by frequency will generate slices.
	// +kubebuilder:validation:Optional
	SlicingExprs []*string `json:"slicingExprs,omitempty" tf:"slicing_exprs,omitempty"`

	// Configuration for monitoring snapshot tables.
	// +kubebuilder:validation:Optional
	Snapshot []QualityMonitorSnapshotParameters `json:"snapshot,omitempty" tf:"snapshot,omitempty"`

	// - The full name of the table to attach the monitor too. Its of the format {catalog}.{schema}.{tableName}
	// +kubebuilder:validation:Optional
	TableName *string `json:"tableName,omitempty" tf:"table_name,omitempty"`

	// Configuration for monitoring timeseries tables.
	// +kubebuilder:validation:Optional
	TimeSeries []QualityMonitorTimeSeriesParameters `json:"timeSeries,omitempty" tf:"time_series,omitempty"`

	// Optional argument to specify the warehouse for dashboard creation. If not specified, the first running warehouse will be used.
	// +kubebuilder:validation:Optional
	WarehouseID *string `json:"warehouseId,omitempty" tf:"warehouse_id,omitempty"`
}

type QualityMonitorScheduleInitParameters struct {

	// string expression that determines when to run the monitor. See Quartz documentation for examples.
	QuartzCronExpression *string `json:"quartzCronExpression,omitempty" tf:"quartz_cron_expression,omitempty"`

	// string with timezone id (e.g., PST) in which to evaluate the Quartz expression.
	TimezoneID *string `json:"timezoneId,omitempty" tf:"timezone_id,omitempty"`
}

type QualityMonitorScheduleObservation struct {

	// Status of the Monitor
	PauseStatus *string `json:"pauseStatus,omitempty" tf:"pause_status,omitempty"`

	// string expression that determines when to run the monitor. See Quartz documentation for examples.
	QuartzCronExpression *string `json:"quartzCronExpression,omitempty" tf:"quartz_cron_expression,omitempty"`

	// string with timezone id (e.g., PST) in which to evaluate the Quartz expression.
	TimezoneID *string `json:"timezoneId,omitempty" tf:"timezone_id,omitempty"`
}

type QualityMonitorScheduleParameters struct {

	// string expression that determines when to run the monitor. See Quartz documentation for examples.
	// +kubebuilder:validation:Optional
	QuartzCronExpression *string `json:"quartzCronExpression" tf:"quartz_cron_expression,omitempty"`

	// string with timezone id (e.g., PST) in which to evaluate the Quartz expression.
	// +kubebuilder:validation:Optional
	TimezoneID *string `json:"timezoneId" tf:"timezone_id,omitempty"`
}

type QualityMonitorSnapshotInitParameters struct {
}

type QualityMonitorSnapshotObservation struct {
}

type QualityMonitorSnapshotParameters struct {
}

type QualityMonitorTimeSeriesInitParameters struct {

	// List of granularities to use when aggregating data into time windows based on their timestamp.
	Granularities []*string `json:"granularities,omitempty" tf:"granularities,omitempty"`

	// Column of the timestamp of predictions
	TimestampCol *string `json:"timestampCol,omitempty" tf:"timestamp_col,omitempty"`
}

type QualityMonitorTimeSeriesObservation struct {

	// List of granularities to use when aggregating data into time windows based on their timestamp.
	Granularities []*string `json:"granularities,omitempty" tf:"granularities,omitempty"`

	// Column of the timestamp of predictions
	TimestampCol *string `json:"timestampCol,omitempty" tf:"timestamp_col,omitempty"`
}

type QualityMonitorTimeSeriesParameters struct {

	// List of granularities to use when aggregating data into time windows based on their timestamp.
	// +kubebuilder:validation:Optional
	Granularities []*string `json:"granularities" tf:"granularities,omitempty"`

	// Column of the timestamp of predictions
	// +kubebuilder:validation:Optional
	TimestampCol *string `json:"timestampCol" tf:"timestamp_col,omitempty"`
}

// QualityMonitorSpec defines the desired state of QualityMonitor
type QualityMonitorSpec struct {
	v1.ResourceSpec `json:",inline"`
	ForProvider     QualityMonitorParameters `json:"forProvider"`
	// THIS IS A BETA FIELD. It will be honored
	// unless the Management Policies feature flag is disabled.
	// InitProvider holds the same fields as ForProvider, with the exception
	// of Identifier and other resource reference fields. The fields that are
	// in InitProvider are merged into ForProvider when the resource is created.
	// The same fields are also added to the terraform ignore_changes hook, to
	// avoid updating them after creation. This is useful for fields that are
	// required on creation, but we do not desire to update them after creation,
	// for example because of an external controller is managing them, like an
	// autoscaler.
	InitProvider QualityMonitorInitParameters `json:"initProvider,omitempty"`
}

// QualityMonitorStatus defines the observed state of QualityMonitor.
type QualityMonitorStatus struct {
	v1.ResourceStatus `json:",inline"`
	AtProvider        QualityMonitorObservation `json:"atProvider,omitempty"`
}

// +kubebuilder:object:root=true
// +kubebuilder:subresource:status
// +kubebuilder:storageversion

// QualityMonitor is the Schema for the QualityMonitors API. ""subcategory: "Unity Catalog"
// +kubebuilder:printcolumn:name="SYNCED",type="string",JSONPath=".status.conditions[?(@.type=='Synced')].status"
// +kubebuilder:printcolumn:name="READY",type="string",JSONPath=".status.conditions[?(@.type=='Ready')].status"
// +kubebuilder:printcolumn:name="EXTERNAL-NAME",type="string",JSONPath=".metadata.annotations.crossplane\\.io/external-name"
// +kubebuilder:printcolumn:name="AGE",type="date",JSONPath=".metadata.creationTimestamp"
// +kubebuilder:resource:scope=Cluster,categories={crossplane,managed,databricks}
type QualityMonitor struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.assetsDir) || (has(self.initProvider) && has(self.initProvider.assetsDir))",message="spec.forProvider.assetsDir is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.outputSchemaName) || (has(self.initProvider) && has(self.initProvider.outputSchemaName))",message="spec.forProvider.outputSchemaName is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.tableName) || (has(self.initProvider) && has(self.initProvider.tableName))",message="spec.forProvider.tableName is a required parameter"
	Spec   QualityMonitorSpec   `json:"spec"`
	Status QualityMonitorStatus `json:"status,omitempty"`
}

// +kubebuilder:object:root=true

// QualityMonitorList contains a list of QualityMonitors
type QualityMonitorList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	Items           []QualityMonitor `json:"items"`
}

// Repository type metadata.
var (
	QualityMonitor_Kind             = "QualityMonitor"
	QualityMonitor_GroupKind        = schema.GroupKind{Group: CRDGroup, Kind: QualityMonitor_Kind}.String()
	QualityMonitor_KindAPIVersion   = QualityMonitor_Kind + "." + CRDGroupVersion.String()
	QualityMonitor_GroupVersionKind = CRDGroupVersion.WithKind(QualityMonitor_Kind)
)

func init() {
	SchemeBuilder.Register(&QualityMonitor{}, &QualityMonitorList{})
}
