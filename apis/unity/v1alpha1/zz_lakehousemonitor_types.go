// SPDX-FileCopyrightText: 2024 The Crossplane Authors <https://crossplane.io>
//
// SPDX-License-Identifier: Apache-2.0

// Code generated by upjet. DO NOT EDIT.

package v1alpha1

import (
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/runtime/schema"

	v1 "github.com/crossplane/crossplane-runtime/apis/common/v1"
)

type CustomMetricsInitParameters struct {

	// create metric definition
	Definition *string `json:"definition,omitempty" tf:"definition,omitempty"`

	// Columns on the monitored table to apply the custom metrics to.
	InputColumns []*string `json:"inputColumns,omitempty" tf:"input_columns,omitempty"`

	// Name of the custom metric.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// The output type of the custom metric.
	OutputDataType *string `json:"outputDataType,omitempty" tf:"output_data_type,omitempty"`

	// The type of the custom metric.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type CustomMetricsObservation struct {

	// create metric definition
	Definition *string `json:"definition,omitempty" tf:"definition,omitempty"`

	// Columns on the monitored table to apply the custom metrics to.
	InputColumns []*string `json:"inputColumns,omitempty" tf:"input_columns,omitempty"`

	// Name of the custom metric.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// The output type of the custom metric.
	OutputDataType *string `json:"outputDataType,omitempty" tf:"output_data_type,omitempty"`

	// The type of the custom metric.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type CustomMetricsParameters struct {

	// create metric definition
	// +kubebuilder:validation:Optional
	Definition *string `json:"definition" tf:"definition,omitempty"`

	// Columns on the monitored table to apply the custom metrics to.
	// +kubebuilder:validation:Optional
	InputColumns []*string `json:"inputColumns" tf:"input_columns,omitempty"`

	// Name of the custom metric.
	// +kubebuilder:validation:Optional
	Name *string `json:"name" tf:"name,omitempty"`

	// The output type of the custom metric.
	// +kubebuilder:validation:Optional
	OutputDataType *string `json:"outputDataType" tf:"output_data_type,omitempty"`

	// The type of the custom metric.
	// +kubebuilder:validation:Optional
	Type *string `json:"type" tf:"type,omitempty"`
}

type DataClassificationConfigInitParameters struct {
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`
}

type DataClassificationConfigObservation struct {
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`
}

type DataClassificationConfigParameters struct {

	// +kubebuilder:validation:Optional
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`
}

type InferenceLogInitParameters struct {

	// List of granularities to use when aggregating data into time windows based on their timestamp.
	Granularities []*string `json:"granularities,omitempty" tf:"granularities,omitempty"`

	// Column of the model label
	LabelCol *string `json:"labelCol,omitempty" tf:"label_col,omitempty"`

	// Column of the model id or version
	ModelIDCol *string `json:"modelIdCol,omitempty" tf:"model_id_col,omitempty"`

	// Column of the model prediction
	PredictionCol *string `json:"predictionCol,omitempty" tf:"prediction_col,omitempty"`

	// Column of the model prediction probabilities
	PredictionProbaCol *string `json:"predictionProbaCol,omitempty" tf:"prediction_proba_col,omitempty"`

	// Problem type the model aims to solve. Either PROBLEM_TYPE_CLASSIFICATION or PROBLEM_TYPE_REGRESSION
	ProblemType *string `json:"problemType,omitempty" tf:"problem_type,omitempty"`

	// Column of the timestamp of predictions
	TimestampCol *string `json:"timestampCol,omitempty" tf:"timestamp_col,omitempty"`
}

type InferenceLogObservation struct {

	// List of granularities to use when aggregating data into time windows based on their timestamp.
	Granularities []*string `json:"granularities,omitempty" tf:"granularities,omitempty"`

	// Column of the model label
	LabelCol *string `json:"labelCol,omitempty" tf:"label_col,omitempty"`

	// Column of the model id or version
	ModelIDCol *string `json:"modelIdCol,omitempty" tf:"model_id_col,omitempty"`

	// Column of the model prediction
	PredictionCol *string `json:"predictionCol,omitempty" tf:"prediction_col,omitempty"`

	// Column of the model prediction probabilities
	PredictionProbaCol *string `json:"predictionProbaCol,omitempty" tf:"prediction_proba_col,omitempty"`

	// Problem type the model aims to solve. Either PROBLEM_TYPE_CLASSIFICATION or PROBLEM_TYPE_REGRESSION
	ProblemType *string `json:"problemType,omitempty" tf:"problem_type,omitempty"`

	// Column of the timestamp of predictions
	TimestampCol *string `json:"timestampCol,omitempty" tf:"timestamp_col,omitempty"`
}

type InferenceLogParameters struct {

	// List of granularities to use when aggregating data into time windows based on their timestamp.
	// +kubebuilder:validation:Optional
	Granularities []*string `json:"granularities" tf:"granularities,omitempty"`

	// Column of the model label
	// +kubebuilder:validation:Optional
	LabelCol *string `json:"labelCol,omitempty" tf:"label_col,omitempty"`

	// Column of the model id or version
	// +kubebuilder:validation:Optional
	ModelIDCol *string `json:"modelIdCol" tf:"model_id_col,omitempty"`

	// Column of the model prediction
	// +kubebuilder:validation:Optional
	PredictionCol *string `json:"predictionCol" tf:"prediction_col,omitempty"`

	// Column of the model prediction probabilities
	// +kubebuilder:validation:Optional
	PredictionProbaCol *string `json:"predictionProbaCol,omitempty" tf:"prediction_proba_col,omitempty"`

	// Problem type the model aims to solve. Either PROBLEM_TYPE_CLASSIFICATION or PROBLEM_TYPE_REGRESSION
	// +kubebuilder:validation:Optional
	ProblemType *string `json:"problemType" tf:"problem_type,omitempty"`

	// Column of the timestamp of predictions
	// +kubebuilder:validation:Optional
	TimestampCol *string `json:"timestampCol" tf:"timestamp_col,omitempty"`
}

type LakehouseMonitorInitParameters struct {

	// - The directory to store the monitoring assets (Eg. Dashboard and Metric Tables)
	AssetsDir *string `json:"assetsDir,omitempty" tf:"assets_dir,omitempty"`

	// Name of the baseline table from which drift metrics are computed from.Columns in the monitored table should also be present in the baseline
	// table.
	BaselineTableName *string `json:"baselineTableName,omitempty" tf:"baseline_table_name,omitempty"`

	// Custom metrics to compute on the monitored table. These can be aggregate metrics, derived metrics (from already computed aggregate metrics), or drift metrics (comparing metrics across time windows).
	CustomMetrics []CustomMetricsInitParameters `json:"customMetrics,omitempty" tf:"custom_metrics,omitempty"`

	// The data classification config for the monitor
	DataClassificationConfig []DataClassificationConfigInitParameters `json:"dataClassificationConfig,omitempty" tf:"data_classification_config,omitempty"`

	// Configuration for the inference log monitor
	InferenceLog []InferenceLogInitParameters `json:"inferenceLog,omitempty" tf:"inference_log,omitempty"`

	LatestMonitorFailureMsg *string `json:"latestMonitorFailureMsg,omitempty" tf:"latest_monitor_failure_msg,omitempty"`

	// The notification settings for the monitor.  The following optional blocks are supported, each consisting of the single string array field with name email_addresses containing a list of emails to notify:
	Notifications []NotificationsInitParameters `json:"notifications,omitempty" tf:"notifications,omitempty"`

	// - Schema where output metric tables are created
	OutputSchemaName *string `json:"outputSchemaName,omitempty" tf:"output_schema_name,omitempty"`

	// The schedule for automatically updating and refreshing metric tables.  This block consists of following fields:
	Schedule []ScheduleInitParameters `json:"schedule,omitempty" tf:"schedule,omitempty"`

	// Whether to skip creating a default dashboard summarizing data quality metrics.
	SkipBuiltinDashboard *bool `json:"skipBuiltinDashboard,omitempty" tf:"skip_builtin_dashboard,omitempty"`

	// List of column expressions to slice data with for targeted analysis. The data is grouped by each expression independently, resulting in a separate slice for each predicate and its complements. For high-cardinality columns, only the top 100 unique values by frequency will generate slices.
	SlicingExprs []*string `json:"slicingExprs,omitempty" tf:"slicing_exprs,omitempty"`

	// Configuration for monitoring snapshot tables.
	Snapshot []SnapshotInitParameters `json:"snapshot,omitempty" tf:"snapshot,omitempty"`

	// - The full name of the table to attach the monitor too. Its of the format {catalog}.{schema}.{tableName}
	TableName *string `json:"tableName,omitempty" tf:"table_name,omitempty"`

	// Configuration for monitoring timeseries tables.
	TimeSeries []TimeSeriesInitParameters `json:"timeSeries,omitempty" tf:"time_series,omitempty"`

	// Optional argument to specify the warehouse for dashboard creation. If not specified, the first running warehouse will be used.
	WarehouseID *string `json:"warehouseId,omitempty" tf:"warehouse_id,omitempty"`
}

type LakehouseMonitorObservation struct {

	// - The directory to store the monitoring assets (Eg. Dashboard and Metric Tables)
	AssetsDir *string `json:"assetsDir,omitempty" tf:"assets_dir,omitempty"`

	// Name of the baseline table from which drift metrics are computed from.Columns in the monitored table should also be present in the baseline
	// table.
	BaselineTableName *string `json:"baselineTableName,omitempty" tf:"baseline_table_name,omitempty"`

	// Custom metrics to compute on the monitored table. These can be aggregate metrics, derived metrics (from already computed aggregate metrics), or drift metrics (comparing metrics across time windows).
	CustomMetrics []CustomMetricsObservation `json:"customMetrics,omitempty" tf:"custom_metrics,omitempty"`

	// The ID of the generated dashboard.
	DashboardID *string `json:"dashboardId,omitempty" tf:"dashboard_id,omitempty"`

	// The data classification config for the monitor
	DataClassificationConfig []DataClassificationConfigObservation `json:"dataClassificationConfig,omitempty" tf:"data_classification_config,omitempty"`

	// The full name of the drift metrics table. Format: catalog_name.schema_name.table_name.
	DriftMetricsTableName *string `json:"driftMetricsTableName,omitempty" tf:"drift_metrics_table_name,omitempty"`

	// ID of this monitor is the same as the full table name of the format {catalog}.{schema_name}.{table_name}
	ID *string `json:"id,omitempty" tf:"id,omitempty"`

	// Configuration for the inference log monitor
	InferenceLog []InferenceLogObservation `json:"inferenceLog,omitempty" tf:"inference_log,omitempty"`

	LatestMonitorFailureMsg *string `json:"latestMonitorFailureMsg,omitempty" tf:"latest_monitor_failure_msg,omitempty"`

	// The version of the monitor config (e.g. 1,2,3). If negative, the monitor may be corrupted
	MonitorVersion *string `json:"monitorVersion,omitempty" tf:"monitor_version,omitempty"`

	// The notification settings for the monitor.  The following optional blocks are supported, each consisting of the single string array field with name email_addresses containing a list of emails to notify:
	Notifications []NotificationsObservation `json:"notifications,omitempty" tf:"notifications,omitempty"`

	// - Schema where output metric tables are created
	OutputSchemaName *string `json:"outputSchemaName,omitempty" tf:"output_schema_name,omitempty"`

	// The full name of the profile metrics table. Format: catalog_name.schema_name.table_name.
	ProfileMetricsTableName *string `json:"profileMetricsTableName,omitempty" tf:"profile_metrics_table_name,omitempty"`

	// The schedule for automatically updating and refreshing metric tables.  This block consists of following fields:
	Schedule []ScheduleObservation `json:"schedule,omitempty" tf:"schedule,omitempty"`

	// Whether to skip creating a default dashboard summarizing data quality metrics.
	SkipBuiltinDashboard *bool `json:"skipBuiltinDashboard,omitempty" tf:"skip_builtin_dashboard,omitempty"`

	// List of column expressions to slice data with for targeted analysis. The data is grouped by each expression independently, resulting in a separate slice for each predicate and its complements. For high-cardinality columns, only the top 100 unique values by frequency will generate slices.
	SlicingExprs []*string `json:"slicingExprs,omitempty" tf:"slicing_exprs,omitempty"`

	// Configuration for monitoring snapshot tables.
	Snapshot []SnapshotParameters `json:"snapshot,omitempty" tf:"snapshot,omitempty"`

	// Status of the Monitor
	Status *string `json:"status,omitempty" tf:"status,omitempty"`

	// - The full name of the table to attach the monitor too. Its of the format {catalog}.{schema}.{tableName}
	TableName *string `json:"tableName,omitempty" tf:"table_name,omitempty"`

	// Configuration for monitoring timeseries tables.
	TimeSeries []TimeSeriesObservation `json:"timeSeries,omitempty" tf:"time_series,omitempty"`

	// Optional argument to specify the warehouse for dashboard creation. If not specified, the first running warehouse will be used.
	WarehouseID *string `json:"warehouseId,omitempty" tf:"warehouse_id,omitempty"`
}

type LakehouseMonitorParameters struct {

	// - The directory to store the monitoring assets (Eg. Dashboard and Metric Tables)
	// +kubebuilder:validation:Optional
	AssetsDir *string `json:"assetsDir,omitempty" tf:"assets_dir,omitempty"`

	// Name of the baseline table from which drift metrics are computed from.Columns in the monitored table should also be present in the baseline
	// table.
	// +kubebuilder:validation:Optional
	BaselineTableName *string `json:"baselineTableName,omitempty" tf:"baseline_table_name,omitempty"`

	// Custom metrics to compute on the monitored table. These can be aggregate metrics, derived metrics (from already computed aggregate metrics), or drift metrics (comparing metrics across time windows).
	// +kubebuilder:validation:Optional
	CustomMetrics []CustomMetricsParameters `json:"customMetrics,omitempty" tf:"custom_metrics,omitempty"`

	// The data classification config for the monitor
	// +kubebuilder:validation:Optional
	DataClassificationConfig []DataClassificationConfigParameters `json:"dataClassificationConfig,omitempty" tf:"data_classification_config,omitempty"`

	// Configuration for the inference log monitor
	// +kubebuilder:validation:Optional
	InferenceLog []InferenceLogParameters `json:"inferenceLog,omitempty" tf:"inference_log,omitempty"`

	// +kubebuilder:validation:Optional
	LatestMonitorFailureMsg *string `json:"latestMonitorFailureMsg,omitempty" tf:"latest_monitor_failure_msg,omitempty"`

	// The notification settings for the monitor.  The following optional blocks are supported, each consisting of the single string array field with name email_addresses containing a list of emails to notify:
	// +kubebuilder:validation:Optional
	Notifications []NotificationsParameters `json:"notifications,omitempty" tf:"notifications,omitempty"`

	// - Schema where output metric tables are created
	// +kubebuilder:validation:Optional
	OutputSchemaName *string `json:"outputSchemaName,omitempty" tf:"output_schema_name,omitempty"`

	// The schedule for automatically updating and refreshing metric tables.  This block consists of following fields:
	// +kubebuilder:validation:Optional
	Schedule []ScheduleParameters `json:"schedule,omitempty" tf:"schedule,omitempty"`

	// Whether to skip creating a default dashboard summarizing data quality metrics.
	// +kubebuilder:validation:Optional
	SkipBuiltinDashboard *bool `json:"skipBuiltinDashboard,omitempty" tf:"skip_builtin_dashboard,omitempty"`

	// List of column expressions to slice data with for targeted analysis. The data is grouped by each expression independently, resulting in a separate slice for each predicate and its complements. For high-cardinality columns, only the top 100 unique values by frequency will generate slices.
	// +kubebuilder:validation:Optional
	SlicingExprs []*string `json:"slicingExprs,omitempty" tf:"slicing_exprs,omitempty"`

	// Configuration for monitoring snapshot tables.
	// +kubebuilder:validation:Optional
	Snapshot []SnapshotParameters `json:"snapshot,omitempty" tf:"snapshot,omitempty"`

	// - The full name of the table to attach the monitor too. Its of the format {catalog}.{schema}.{tableName}
	// +kubebuilder:validation:Optional
	TableName *string `json:"tableName,omitempty" tf:"table_name,omitempty"`

	// Configuration for monitoring timeseries tables.
	// +kubebuilder:validation:Optional
	TimeSeries []TimeSeriesParameters `json:"timeSeries,omitempty" tf:"time_series,omitempty"`

	// Optional argument to specify the warehouse for dashboard creation. If not specified, the first running warehouse will be used.
	// +kubebuilder:validation:Optional
	WarehouseID *string `json:"warehouseId,omitempty" tf:"warehouse_id,omitempty"`
}

type NotificationsInitParameters struct {

	// who to send notifications to on monitor failure.
	OnFailure []OnFailureInitParameters `json:"onFailure,omitempty" tf:"on_failure,omitempty"`

	// Who to send notifications to when new data classification tags are detected.
	OnNewClassificationTagDetected []OnNewClassificationTagDetectedInitParameters `json:"onNewClassificationTagDetected,omitempty" tf:"on_new_classification_tag_detected,omitempty"`
}

type NotificationsObservation struct {

	// who to send notifications to on monitor failure.
	OnFailure []OnFailureObservation `json:"onFailure,omitempty" tf:"on_failure,omitempty"`

	// Who to send notifications to when new data classification tags are detected.
	OnNewClassificationTagDetected []OnNewClassificationTagDetectedObservation `json:"onNewClassificationTagDetected,omitempty" tf:"on_new_classification_tag_detected,omitempty"`
}

type NotificationsParameters struct {

	// who to send notifications to on monitor failure.
	// +kubebuilder:validation:Optional
	OnFailure []OnFailureParameters `json:"onFailure,omitempty" tf:"on_failure,omitempty"`

	// Who to send notifications to when new data classification tags are detected.
	// +kubebuilder:validation:Optional
	OnNewClassificationTagDetected []OnNewClassificationTagDetectedParameters `json:"onNewClassificationTagDetected,omitempty" tf:"on_new_classification_tag_detected,omitempty"`
}

type OnFailureInitParameters struct {
	EmailAddresses []*string `json:"emailAddresses,omitempty" tf:"email_addresses,omitempty"`
}

type OnFailureObservation struct {
	EmailAddresses []*string `json:"emailAddresses,omitempty" tf:"email_addresses,omitempty"`
}

type OnFailureParameters struct {

	// +kubebuilder:validation:Optional
	EmailAddresses []*string `json:"emailAddresses,omitempty" tf:"email_addresses,omitempty"`
}

type OnNewClassificationTagDetectedInitParameters struct {
	EmailAddresses []*string `json:"emailAddresses,omitempty" tf:"email_addresses,omitempty"`
}

type OnNewClassificationTagDetectedObservation struct {
	EmailAddresses []*string `json:"emailAddresses,omitempty" tf:"email_addresses,omitempty"`
}

type OnNewClassificationTagDetectedParameters struct {

	// +kubebuilder:validation:Optional
	EmailAddresses []*string `json:"emailAddresses,omitempty" tf:"email_addresses,omitempty"`
}

type ScheduleInitParameters struct {

	// string expression that determines when to run the monitor. See Quartz documentation for examples.
	QuartzCronExpression *string `json:"quartzCronExpression,omitempty" tf:"quartz_cron_expression,omitempty"`

	// string with timezone id (e.g., PST) in which to evaluate the Quartz expression.
	TimezoneID *string `json:"timezoneId,omitempty" tf:"timezone_id,omitempty"`
}

type ScheduleObservation struct {

	// optional string field that indicates whether a schedule is paused (PAUSED) or not (UNPAUSED).
	PauseStatus *string `json:"pauseStatus,omitempty" tf:"pause_status,omitempty"`

	// string expression that determines when to run the monitor. See Quartz documentation for examples.
	QuartzCronExpression *string `json:"quartzCronExpression,omitempty" tf:"quartz_cron_expression,omitempty"`

	// string with timezone id (e.g., PST) in which to evaluate the Quartz expression.
	TimezoneID *string `json:"timezoneId,omitempty" tf:"timezone_id,omitempty"`
}

type ScheduleParameters struct {

	// string expression that determines when to run the monitor. See Quartz documentation for examples.
	// +kubebuilder:validation:Optional
	QuartzCronExpression *string `json:"quartzCronExpression" tf:"quartz_cron_expression,omitempty"`

	// string with timezone id (e.g., PST) in which to evaluate the Quartz expression.
	// +kubebuilder:validation:Optional
	TimezoneID *string `json:"timezoneId" tf:"timezone_id,omitempty"`
}

type SnapshotInitParameters struct {
}

type SnapshotObservation struct {
}

type SnapshotParameters struct {
}

type TimeSeriesInitParameters struct {

	// List of granularities to use when aggregating data into time windows based on their timestamp.
	Granularities []*string `json:"granularities,omitempty" tf:"granularities,omitempty"`

	// Column of the timestamp of predictions
	TimestampCol *string `json:"timestampCol,omitempty" tf:"timestamp_col,omitempty"`
}

type TimeSeriesObservation struct {

	// List of granularities to use when aggregating data into time windows based on their timestamp.
	Granularities []*string `json:"granularities,omitempty" tf:"granularities,omitempty"`

	// Column of the timestamp of predictions
	TimestampCol *string `json:"timestampCol,omitempty" tf:"timestamp_col,omitempty"`
}

type TimeSeriesParameters struct {

	// List of granularities to use when aggregating data into time windows based on their timestamp.
	// +kubebuilder:validation:Optional
	Granularities []*string `json:"granularities" tf:"granularities,omitempty"`

	// Column of the timestamp of predictions
	// +kubebuilder:validation:Optional
	TimestampCol *string `json:"timestampCol" tf:"timestamp_col,omitempty"`
}

// LakehouseMonitorSpec defines the desired state of LakehouseMonitor
type LakehouseMonitorSpec struct {
	v1.ResourceSpec `json:",inline"`
	ForProvider     LakehouseMonitorParameters `json:"forProvider"`
	// THIS IS A BETA FIELD. It will be honored
	// unless the Management Policies feature flag is disabled.
	// InitProvider holds the same fields as ForProvider, with the exception
	// of Identifier and other resource reference fields. The fields that are
	// in InitProvider are merged into ForProvider when the resource is created.
	// The same fields are also added to the terraform ignore_changes hook, to
	// avoid updating them after creation. This is useful for fields that are
	// required on creation, but we do not desire to update them after creation,
	// for example because of an external controller is managing them, like an
	// autoscaler.
	InitProvider LakehouseMonitorInitParameters `json:"initProvider,omitempty"`
}

// LakehouseMonitorStatus defines the observed state of LakehouseMonitor.
type LakehouseMonitorStatus struct {
	v1.ResourceStatus `json:",inline"`
	AtProvider        LakehouseMonitorObservation `json:"atProvider,omitempty"`
}

// +kubebuilder:object:root=true
// +kubebuilder:subresource:status
// +kubebuilder:storageversion

// LakehouseMonitor is the Schema for the LakehouseMonitors API. ""subcategory: "Unity Catalog"
// +kubebuilder:printcolumn:name="SYNCED",type="string",JSONPath=".status.conditions[?(@.type=='Synced')].status"
// +kubebuilder:printcolumn:name="READY",type="string",JSONPath=".status.conditions[?(@.type=='Ready')].status"
// +kubebuilder:printcolumn:name="EXTERNAL-NAME",type="string",JSONPath=".metadata.annotations.crossplane\\.io/external-name"
// +kubebuilder:printcolumn:name="AGE",type="date",JSONPath=".metadata.creationTimestamp"
// +kubebuilder:resource:scope=Cluster,categories={crossplane,managed,}
type LakehouseMonitor struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.assetsDir) || (has(self.initProvider) && has(self.initProvider.assetsDir))",message="spec.forProvider.assetsDir is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.outputSchemaName) || (has(self.initProvider) && has(self.initProvider.outputSchemaName))",message="spec.forProvider.outputSchemaName is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.tableName) || (has(self.initProvider) && has(self.initProvider.tableName))",message="spec.forProvider.tableName is a required parameter"
	Spec   LakehouseMonitorSpec   `json:"spec"`
	Status LakehouseMonitorStatus `json:"status,omitempty"`
}

// +kubebuilder:object:root=true

// LakehouseMonitorList contains a list of LakehouseMonitors
type LakehouseMonitorList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	Items           []LakehouseMonitor `json:"items"`
}

// Repository type metadata.
var (
	LakehouseMonitor_Kind             = "LakehouseMonitor"
	LakehouseMonitor_GroupKind        = schema.GroupKind{Group: CRDGroup, Kind: LakehouseMonitor_Kind}.String()
	LakehouseMonitor_KindAPIVersion   = LakehouseMonitor_Kind + "." + CRDGroupVersion.String()
	LakehouseMonitor_GroupVersionKind = CRDGroupVersion.WithKind(LakehouseMonitor_Kind)
)

func init() {
	SchemeBuilder.Register(&LakehouseMonitor{}, &LakehouseMonitorList{})
}
